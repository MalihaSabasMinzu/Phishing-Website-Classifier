{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c3ada6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3880/3975393700.py:12: DtypeWarning: Columns (46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  processed_features_df = pd.read_csv(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_id</th>\n",
       "      <th>url</th>\n",
       "      <th>website</th>\n",
       "      <th>result</th>\n",
       "      <th>created_date</th>\n",
       "      <th>webpage_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>http://intego3.info/EXEL/index.php</td>\n",
       "      <td>1613573972338075.html</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-02-17 20:29:32</td>\n",
       "      <td>&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.mathopenref.com/segment.html</td>\n",
       "      <td>1635698138155948.html</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-10-31 16:35:38</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html&gt;\\n &lt;head&gt;\\n  &lt;title&gt;\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://www.computerhope.com/issues/ch000254.htm</td>\n",
       "      <td>1635699228889266.html</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-10-31 16:53:48</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;!--[if lt IE 7]&gt;&lt;html class=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.investopedia.com/terms/n/next-elev...</td>\n",
       "      <td>1635750062162701.html</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-11-01 12:31:02</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html class=\"comp no-js terms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://jobs.emss.org.uk/lcc.aspx</td>\n",
       "      <td>161356510250721.html</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-17 18:01:42</td>\n",
       "      <td>&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rec_id                                                url  \\\n",
       "0       1                 http://intego3.info/EXEL/index.php   \n",
       "1       2           https://www.mathopenref.com/segment.html   \n",
       "2       3   https://www.computerhope.com/issues/ch000254.htm   \n",
       "3       4  https://www.investopedia.com/terms/n/next-elev...   \n",
       "4       5                  https://jobs.emss.org.uk/lcc.aspx   \n",
       "\n",
       "                 website  result         created_date  \\\n",
       "0  1613573972338075.html       1  2021-02-17 20:29:32   \n",
       "1  1635698138155948.html       0  2021-10-31 16:35:38   \n",
       "2  1635699228889266.html       0  2021-10-31 16:53:48   \n",
       "3  1635750062162701.html       0  2021-11-01 12:31:02   \n",
       "4   161356510250721.html       0  2021-02-17 18:01:42   \n",
       "\n",
       "                                        webpage_code  \n",
       "0  <!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 T...  \n",
       "1  <!DOCTYPE html>\\n<html>\\n <head>\\n  <title>\\n ...  \n",
       "2  <!DOCTYPE html>\\n<!--[if lt IE 7]><html class=...  \n",
       "3  <!DOCTYPE html>\\n<html class=\"comp no-js terms...  \n",
       "4  <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 T...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessed dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_id</th>\n",
       "      <th>url</th>\n",
       "      <th>result</th>\n",
       "      <th>created_date</th>\n",
       "      <th>webpage_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>http://intego3.info/EXEL/index.php</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-02-17 20:29:32</td>\n",
       "      <td>&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.mathopenref.com/segment.html</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-10-31 16:35:38</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html&gt;\\n &lt;head&gt;\\n &lt;title&gt;\\n S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://www.computerhope.com/issues/ch000254.htm</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-10-31 16:53:48</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html itemscope=\"\" itemtype=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.investopedia.com/terms/n/next-elev...</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-11-01 12:31:02</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html class=\"comp no-js terms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://jobs.emss.org.uk/lcc.aspx</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-17 18:01:42</td>\n",
       "      <td>&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rec_id                                                url  result  \\\n",
       "0       1                 http://intego3.info/EXEL/index.php       1   \n",
       "1       2           https://www.mathopenref.com/segment.html       0   \n",
       "2       3   https://www.computerhope.com/issues/ch000254.htm       0   \n",
       "3       4  https://www.investopedia.com/terms/n/next-elev...       0   \n",
       "4       5                  https://jobs.emss.org.uk/lcc.aspx       0   \n",
       "\n",
       "          created_date                                       webpage_code  \n",
       "0  2021-02-17 20:29:32  <!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 T...  \n",
       "1  2021-10-31 16:35:38  <!DOCTYPE html>\\n<html>\\n <head>\\n <title>\\n S...  \n",
       "2  2021-10-31 16:53:48  <!DOCTYPE html>\\n<html itemscope=\"\" itemtype=\"...  \n",
       "3  2021-11-01 12:31:02  <!DOCTYPE html>\\n<html class=\"comp no-js terms...  \n",
       "4  2021-02-17 18:01:42  <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 T...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed features dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_tags</th>\n",
       "      <th>div_count</th>\n",
       "      <th>script_count</th>\n",
       "      <th>iframe_count</th>\n",
       "      <th>form_count</th>\n",
       "      <th>input_count</th>\n",
       "      <th>a_tag_count</th>\n",
       "      <th>img_count</th>\n",
       "      <th>meta_count</th>\n",
       "      <th>max_nesting_depth</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio_official_assets</th>\n",
       "      <th>hotlinking_official_assets</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>phishing_keyword_count</th>\n",
       "      <th>exclamation_count</th>\n",
       "      <th>question_count</th>\n",
       "      <th>special_char_ratio</th>\n",
       "      <th>rec_id</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>575</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.116522</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3373</td>\n",
       "      <td>355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142010</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>642</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11553</td>\n",
       "      <td>1501</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.032978</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1635</td>\n",
       "      <td>227</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>33587</td>\n",
       "      <td>2707</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.150296</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>819</td>\n",
       "      <td>94</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>58</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8022</td>\n",
       "      <td>652</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.063201</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_tags  div_count  script_count  iframe_count  form_count  input_count  \\\n",
       "0          43          7             1             0           1            4   \n",
       "1         100         17             4             0           2            3   \n",
       "2         642         19             8             0           2            2   \n",
       "3        1635        227             6             1           1            1   \n",
       "4         819         94            17             1           1            8   \n",
       "\n",
       "   a_tag_count  img_count  meta_count  max_nesting_depth  ...  \\\n",
       "0            1          4           1                  1  ...   \n",
       "1            7          2           4                  1  ...   \n",
       "2           77          5          19                  1  ...   \n",
       "3          150         19          32                  1  ...   \n",
       "4           58         12           4                  1  ...   \n",
       "\n",
       "   ratio_official_assets  hotlinking_official_assets  text_length  word_count  \\\n",
       "0                    0.0                           0          575          46   \n",
       "1                    0.0                           0         3373         355   \n",
       "2                    0.0                           0        11553        1501   \n",
       "3                    0.0                           0        33587        2707   \n",
       "4                    0.0                           0         8022         652   \n",
       "\n",
       "   phishing_keyword_count  exclamation_count  question_count  \\\n",
       "0                       2                  0               0   \n",
       "1                       0                  0               0   \n",
       "2                       2                  1               5   \n",
       "3                       2                  3              12   \n",
       "4                       1                  1               2   \n",
       "\n",
       "   special_char_ratio  rec_id  result  \n",
       "0            0.116522       1       1  \n",
       "1            0.142010       2       0  \n",
       "2            0.032978       3       0  \n",
       "3            0.150296       4       0  \n",
       "4            0.063201       5       0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 80000 entries, 0 to 79999\n",
      "Data columns (total 81 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   total_tags                    80000 non-null  int64  \n",
      " 1   div_count                     80000 non-null  int64  \n",
      " 2   script_count                  80000 non-null  int64  \n",
      " 3   iframe_count                  80000 non-null  int64  \n",
      " 4   form_count                    80000 non-null  int64  \n",
      " 5   input_count                   80000 non-null  int64  \n",
      " 6   a_tag_count                   80000 non-null  int64  \n",
      " 7   img_count                     80000 non-null  int64  \n",
      " 8   meta_count                    80000 non-null  int64  \n",
      " 9   max_nesting_depth             80000 non-null  int64  \n",
      " 10  unclosed_tags                 80000 non-null  int64  \n",
      " 11  has_doctype                   80000 non-null  int64  \n",
      " 12  html_length                   80000 non-null  int64  \n",
      " 13  html_length_log               80000 non-null  float64\n",
      " 14  password_field_count          80000 non-null  int64  \n",
      " 15  email_field_count             80000 non-null  int64  \n",
      " 16  text_input_count              80000 non-null  int64  \n",
      " 17  hidden_input_count            80000 non-null  int64  \n",
      " 18  submit_button_count           80000 non-null  int64  \n",
      " 19  form_has_external_action      80000 non-null  int64  \n",
      " 20  form_action_suspicious        80000 non-null  int64  \n",
      " 21  total_script_length           80000 non-null  int64  \n",
      " 22  has_eval                      80000 non-null  int64  \n",
      " 23  has_unescape                  80000 non-null  int64  \n",
      " 24  has_document_write            80000 non-null  int64  \n",
      " 25  has_settimeout                80000 non-null  int64  \n",
      " 26  has_setinterval               80000 non-null  int64  \n",
      " 27  has_unicode_escape            80000 non-null  int64  \n",
      " 28  has_hex_escape                80000 non-null  int64  \n",
      " 29  has_base64                    80000 non-null  int64  \n",
      " 30  has_packed_js                 80000 non-null  int64  \n",
      " 31  has_charcodeat                80000 non-null  int64  \n",
      " 32  has_fromcharcode              80000 non-null  int64  \n",
      " 33  unicode_escape_count          80000 non-null  int64  \n",
      " 34  url_encoding_count            80000 non-null  int64  \n",
      " 35  js_entropy                    80000 non-null  float64\n",
      " 36  high_entropy_js               80000 non-null  int64  \n",
      " 37  total_links                   80000 non-null  int64  \n",
      " 38  external_links                80000 non-null  int64  \n",
      " 39  suspicious_tld_count          80000 non-null  int64  \n",
      " 40  ip_in_url                     80000 non-null  int64  \n",
      " 41  external_resources            80000 non-null  int64  \n",
      " 42  url_text_mismatch             80000 non-null  int64  \n",
      " 43  total_image_area              80000 non-null  int64  \n",
      " 44  image_to_text_ratio           80000 non-null  float64\n",
      " 45  high_image_to_text            80000 non-null  int64  \n",
      " 46  max_z_index                   80000 non-null  object \n",
      " 47  z_index_range                 80000 non-null  object \n",
      " 48  high_z_index_elements         80000 non-null  int64  \n",
      " 49  absolute_position_count       80000 non-null  int64  \n",
      " 50  overlay_pattern               80000 non-null  int64  \n",
      " 51  font_size_zero                80000 non-null  int64  \n",
      " 52  opacity_zero                  80000 non-null  int64  \n",
      " 53  negative_position             80000 non-null  int64  \n",
      " 54  display_none                  80000 non-null  int64  \n",
      " 55  hidden_text_techniques        80000 non-null  int64  \n",
      " 56  delayed_password_reveal       80000 non-null  int64  \n",
      " 57  delayed_dom_modification      80000 non-null  int64  \n",
      " 58  blocks_security_hotkeys       80000 non-null  int64  \n",
      " 59  brand_mention_count           80000 non-null  int64  \n",
      " 60  domain_brand_mismatch         80000 non-null  int64  \n",
      " 61  form_action_to_free_host      80000 non-null  int64  \n",
      " 62  form_action_different_domain  80000 non-null  int64  \n",
      " 63  has_favicon                   80000 non-null  int64  \n",
      " 64  favicon_external              80000 non-null  int64  \n",
      " 65  brands_near_password_field    80000 non-null  int64  \n",
      " 66  title_has_brand               80000 non-null  int64  \n",
      " 67  brand_password_distance       80000 non-null  int64  \n",
      " 68  brand_password_far            80000 non-null  int64  \n",
      " 69  total_resources               80000 non-null  int64  \n",
      " 70  official_brand_resources      80000 non-null  int64  \n",
      " 71  ratio_official_assets         80000 non-null  float64\n",
      " 72  hotlinking_official_assets    80000 non-null  int64  \n",
      " 73  text_length                   80000 non-null  int64  \n",
      " 74  word_count                    80000 non-null  int64  \n",
      " 75  phishing_keyword_count        80000 non-null  int64  \n",
      " 76  exclamation_count             80000 non-null  int64  \n",
      " 77  question_count                80000 non-null  int64  \n",
      " 78  special_char_ratio            80000 non-null  float64\n",
      " 79  rec_id                        80000 non-null  int64  \n",
      " 80  result                        80000 non-null  int64  \n",
      "dtypes: float64(5), int64(74), object(2)\n",
      "memory usage: 49.4+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "first_df = pd.read_csv(\n",
    "    \"/home/maliha/Programming/dm/Phishing-Website-Classifier/phishing_complete_dataset.csv\",\n",
    "    nrows=10,\n",
    ")\n",
    "preprocessed_df = pd.read_csv(\n",
    "    \"/home/maliha/Programming/dm/Phishing-Website-Classifier/phishing_complete_dataset_preprocessed.csv\",\n",
    "    nrows=10,\n",
    ")\n",
    "processed_features_df = pd.read_csv(\n",
    "    \"/home/maliha/Programming/dm/Phishing-Website-Classifier/phishing_complete_features.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"First dataset:\")\n",
    "display(first_df.head())\n",
    "print(\"\\nPreprocessed dataset:\")\n",
    "display(preprocessed_df.head())\n",
    "print(\"\\nProcessed features dataset:\")\n",
    "display(processed_features_df.head())\n",
    "processed_features_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864b9435",
   "metadata": {},
   "source": [
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c503a3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def remove_surrogates(text: str) -> str:\n",
    "    \"\"\"Remove unpaired surrogate characters to prevent encoding errors\"\"\"\n",
    "    try:\n",
    "        return text.encode(\"utf-8\", errors=\"surrogatepass\").decode(\n",
    "            \"utf-8\", errors=\"ignore\"\n",
    "        )\n",
    "    except:\n",
    "        return re.sub(r\"[\\ud800-\\udfff]\", \"\", text)\n",
    "\n",
    "\n",
    "def remove_html_comments(text: str) -> str:\n",
    "    \"\"\"Remove HTML comments using regex (preserves raw HTML structure)\"\"\"\n",
    "    text = re.sub(r\"<!--.*?-->\", \"\", text, flags=re.DOTALL)\n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocess_webpage_code(html_code):\n",
    "    \"\"\"\n",
    "    Preprocess webpage_code column only.\n",
    "\n",
    "    Steps:\n",
    "    1. Remove surrogates (prevents crashes)\n",
    "    2. Remove HTML comments (pure noise)\n",
    "    3. Normalize whitespace (reduces noise)\n",
    "    \"\"\"\n",
    "    if pd.isna(html_code) or html_code == \"\":\n",
    "        return \"\"\n",
    "\n",
    "    try:\n",
    "        text = str(html_code)\n",
    "\n",
    "        # Step 1: Remove surrogates\n",
    "        text = remove_surrogates(text)\n",
    "\n",
    "        # Step 2: Remove HTML comments\n",
    "        text = remove_html_comments(text)\n",
    "\n",
    "        # Step 3: Normalize whitespace\n",
    "        text = re.sub(r\"\\n\\s*\\n\", \"\\n\", text)  # Remove blank lines\n",
    "        text = re.sub(r\"[ \\t]+\", \" \", text)  # Multiple spaces -> single space\n",
    "        text = text.strip()\n",
    "\n",
    "        return text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row: {str(e)[:100]}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "dataset = pd.read_csv(\n",
    "    \"/kaggle/input/phishing-website-webcode-dataset/phishing_complete_dataset.csv\",\n",
    "    sep=\",\",\n",
    "    quotechar='\"',\n",
    ")\n",
    "print(f\"Original dataset shape: {dataset.shape}\")\n",
    "print(f\"Columns: {dataset.columns.tolist()}\")\n",
    "\n",
    "# Check missing values before\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Missing values BEFORE:\")\n",
    "print(\"=\" * 60)\n",
    "print(dataset.isnull().sum())\n",
    "\n",
    "# ========== STEP 1: DROP WEBSITE COLUMN ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 1: Dropping 'website' column...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if \"website\" in dataset.columns:\n",
    "    dataset = dataset.drop(\"website\", axis=1)\n",
    "    print(\"✓ 'website' column dropped\")\n",
    "else:\n",
    "    print(\"⚠ 'website' column not found in dataset\")\n",
    "\n",
    "print(f\"New dataset shape: {dataset.shape}\")\n",
    "print(f\"Remaining columns: {dataset.columns.tolist()}\")\n",
    "\n",
    "# ========== STEP 2: REMOVE ROWS WITH MISSING VALUES ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 2: Removing rows with missing values...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "rows_before = len(dataset)\n",
    "print(f\"Rows before removing missing values: {rows_before}\")\n",
    "\n",
    "# Remove rows with ANY missing values\n",
    "dataset.dropna(inplace=True)\n",
    "\n",
    "dataset.drop_duplicates(inplace=True)\n",
    "\n",
    "rows_after = len(dataset)\n",
    "rows_removed = rows_before - rows_after\n",
    "\n",
    "print(f\"Rows after removing missing values: {rows_after}\")\n",
    "print(f\"Rows removed: {rows_removed} ({(rows_removed/rows_before)*100:.2f}%)\")\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(\"\\nMissing values after removal:\")\n",
    "print(dataset.isnull().sum())\n",
    "\n",
    "# ========== STEP 3: PREPROCESS WEBPAGE_CODE ONLY ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 3: Preprocessing 'webpage_code' column only...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Show before example\n",
    "print(\"\\nBEFORE preprocessing (first 500 chars):\")\n",
    "print(\"-\" * 60)\n",
    "sample_raw = dataset[\"webpage_code\"].iloc[0]\n",
    "print(sample_raw[:500] if pd.notna(sample_raw) else \"N/A\")\n",
    "\n",
    "# Apply preprocessing ONLY to webpage_code column\n",
    "print(\"\\nApplying preprocessing...\")\n",
    "dataset[\"webpage_code\"] = dataset[\"webpage_code\"].apply(preprocess_webpage_code)\n",
    "\n",
    "# Show after example\n",
    "print(\"\\nAFTER preprocessing (first 500 chars):\")\n",
    "print(\"-\" * 60)\n",
    "print(dataset[\"webpage_code\"].iloc[0][:500])\n",
    "\n",
    "# Statistics\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Statistics:\")\n",
    "print(\"=\" * 60)\n",
    "print(\n",
    "    f\"Average webpage_code length: {dataset['webpage_code'].str.len().mean():.0f} chars\"\n",
    ")\n",
    "print(f\"Min webpage_code length: {dataset['webpage_code'].str.len().min():.0f} chars\")\n",
    "print(f\"Max webpage_code length: {dataset['webpage_code'].str.len().max():.0f} chars\")\n",
    "\n",
    "# ========== STEP 4: SAVE PREPROCESSED DATASET ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 4: Saving preprocessed dataset...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    dataset.to_csv(\n",
    "        \"/kaggle/working/phishing_complete_dataset_preprocessed.csv\",\n",
    "        index=False,\n",
    "        encoding=\"utf-8\",\n",
    "        errors=\"surrogatepass\",\n",
    "    )\n",
    "    print(\"✓ Successfully saved to: phishing_complete_dataset_preprocessed.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error saving CSV with surrogatepass: {e}\")\n",
    "    print(\"\\nTrying alternative save method...\")\n",
    "\n",
    "    # Only clean webpage_code if there's an issue\n",
    "    dataset[\"webpage_code\"] = dataset[\"webpage_code\"].apply(\n",
    "        lambda x: remove_surrogates(str(x)) if pd.notna(x) else x\n",
    "    )\n",
    "\n",
    "    dataset.to_csv(\n",
    "        \"/kaggle/working/phishing_complete_dataset_preprocessed.csv\",\n",
    "        index=False,\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "    print(\"✓ Saved with alternative method\")\n",
    "\n",
    "# Final verification\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL VERIFICATION:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Final shape: {dataset.shape}\")\n",
    "print(f\"Final columns: {dataset.columns.tolist()}\")\n",
    "print(\"\\nDataset info:\")\n",
    "print(dataset.info())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"✓ PREPROCESSING COMPLETE!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ee1ff4",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40f066c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 24000/80000 (30.0%)\n",
      "Progress: 25000/80000 (31.2%)\n",
      "Progress: 26000/80000 (32.5%)\n",
      "Progress: 27000/80000 (33.8%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import math\n",
    "from typing import Dict, Optional, List, Tuple\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION & CONSTANTS\n",
    "# ============================================================================\n",
    "\n",
    "BRAND_KEYWORDS = {\n",
    "    \"microsoft\": [\"microsoft.com\", \"office.com\", \"outlook.com\", \"live.com\"],\n",
    "    \"google\": [\"google.com\", \"gmail.com\"],\n",
    "    \"apple\": [\"apple.com\", \"icloud.com\"],\n",
    "    \"paypal\": [\"paypal.com\"],\n",
    "    \"facebook\": [\"facebook.com\", \"fb.com\"],\n",
    "    \"amazon\": [\"amazon.com\"],\n",
    "    \"netflix\": [\"netflix.com\"],\n",
    "    \"dropbox\": [\"dropbox.com\"],\n",
    "    \"adobe\": [\"adobe.com\"],\n",
    "    \"linkedin\": [\"linkedin.com\"],\n",
    "    \"twitter\": [\"twitter.com\", \"x.com\"],\n",
    "    \"instagram\": [\"instagram.com\"],\n",
    "    \"ebay\": [\"ebay.com\"],\n",
    "    \"wells fargo\": [\"wellsfargo.com\"],\n",
    "    \"chase\": [\"chase.com\"],\n",
    "    \"bank of america\": [\"bankofamerica.com\"],\n",
    "}\n",
    "\n",
    "FREE_HOSTING_DOMAINS = [\n",
    "    \"000webhost\",\n",
    "    \"firebaseapp\",\n",
    "    \"formspree\",\n",
    "    \"herokuapp\",\n",
    "    \"netlify.app\",\n",
    "    \"github.io\",\n",
    "    \"gitlab.io\",\n",
    "    \"weebly.com\",\n",
    "    \"wix.com\",\n",
    "    \"wordpress.com\",\n",
    "    \"blogspot.com\",\n",
    "    \"tumblr.com\",\n",
    "    \"surge.sh\",\n",
    "    \"vercel.app\",\n",
    "    \"pages.dev\",\n",
    "    \"infinityfree\",\n",
    "    \"freehosting\",\n",
    "    \"rf.gd\",\n",
    "    \"ucoz.\",\n",
    "]\n",
    "\n",
    "PHISHING_KEYWORDS = [\n",
    "    \"verify\",\n",
    "    \"account\",\n",
    "    \"suspended\",\n",
    "    \"confirm\",\n",
    "    \"update\",\n",
    "    \"secure\",\n",
    "    \"login\",\n",
    "    \"password\",\n",
    "    \"urgent\",\n",
    "    \"immediately\",\n",
    "    \"expire\",\n",
    "    \"limited\",\n",
    "]\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def safe_divide(numerator: float, denominator: float, default: float = 0.0) -> float:\n",
    "    \"\"\"Safely divide two numbers, returning default if denominator is 0\"\"\"\n",
    "    return numerator / denominator if denominator != 0 else default\n",
    "\n",
    "\n",
    "def extract_domain(url: Optional[str]) -> str:\n",
    "    \"\"\"Extract domain from URL safely\"\"\"\n",
    "    if not url:\n",
    "        return \"\"\n",
    "    try:\n",
    "        return urlparse(url).netloc.lower()\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def calculate_shannon_entropy(text: str) -> float:\n",
    "    \"\"\"Calculate Shannon entropy (measure of randomness/obfuscation)\"\"\"\n",
    "    if not text:\n",
    "        return 0.0\n",
    "\n",
    "    counter = Counter(text)\n",
    "    length = len(text)\n",
    "\n",
    "    entropy = 0.0\n",
    "    for count in counter.values():\n",
    "        probability = count / length\n",
    "        entropy -= probability * math.log2(probability)\n",
    "\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def extract_all_scripts(html: str) -> str:\n",
    "    \"\"\"Extract and concatenate all script content\"\"\"\n",
    "    scripts = re.findall(r\"<script[^>]*>(.*?)</script>\", html, re.DOTALL | re.I)\n",
    "    return \"\\n\".join(scripts)\n",
    "\n",
    "\n",
    "def get_text_content(html: str) -> str:\n",
    "    \"\"\"Remove all HTML tags to get plain text\"\"\"\n",
    "    return re.sub(r\"<[^>]+>\", \" \", html)\n",
    "\n",
    "\n",
    "def extract_structural_features(html: str) -> Dict[str, float]:\n",
    "    \"\"\"Extract DOM structure and complexity features\"\"\"\n",
    "    features = {}\n",
    "\n",
    "    # Tag counts\n",
    "    features[\"total_tags\"] = len(re.findall(r\"<[^>]+>\", html))\n",
    "    features[\"div_count\"] = html.count(\"<div\")\n",
    "    features[\"script_count\"] = html.count(\"<script\")\n",
    "    features[\"iframe_count\"] = html.count(\"<iframe\")\n",
    "    features[\"form_count\"] = html.count(\"<form\")\n",
    "    features[\"input_count\"] = html.count(\"<input\")\n",
    "    features[\"a_tag_count\"] = html.count(\"<a \")\n",
    "    features[\"img_count\"] = html.count(\"<img\")\n",
    "    features[\"meta_count\"] = html.count(\"<meta\")\n",
    "\n",
    "    # Nesting depth (approximation)\n",
    "    max_depth = 0\n",
    "    current_depth = 0\n",
    "    for char in html:\n",
    "        if char == \"<\":\n",
    "            current_depth += 1\n",
    "            max_depth = max(max_depth, current_depth)\n",
    "        elif char == \">\":\n",
    "            current_depth = max(0, current_depth - 1)\n",
    "    features[\"max_nesting_depth\"] = max_depth\n",
    "\n",
    "    # Malformed HTML\n",
    "    opening_tags = len(re.findall(r\"<(?!/)(?!!)[a-zA-Z][^>]*>\", html))\n",
    "    closing_tags = len(re.findall(r\"</[a-zA-Z][^>]*>\", html))\n",
    "    features[\"unclosed_tags\"] = abs(opening_tags - closing_tags)\n",
    "    features[\"has_doctype\"] = 1 if \"<!DOCTYPE\" in html.upper() else 0\n",
    "\n",
    "    # HTML length\n",
    "    features[\"html_length\"] = len(html)\n",
    "    features[\"html_length_log\"] = np.log1p(len(html))\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_form_features(html: str) -> Dict[str, float]:\n",
    "    \"\"\"Extract features related to forms and inputs\"\"\"\n",
    "    features = {}\n",
    "\n",
    "    # Input field types\n",
    "    features[\"password_field_count\"] = len(\n",
    "        re.findall(r'type\\s*=\\s*[\"\\']password[\"\\']', html, re.I)\n",
    "    )\n",
    "    features[\"email_field_count\"] = len(\n",
    "        re.findall(r'type\\s*=\\s*[\"\\']email[\"\\']', html, re.I)\n",
    "    )\n",
    "    features[\"text_input_count\"] = len(\n",
    "        re.findall(r'type\\s*=\\s*[\"\\']text[\"\\']', html, re.I)\n",
    "    )\n",
    "    features[\"hidden_input_count\"] = len(\n",
    "        re.findall(r'type\\s*=\\s*[\"\\']hidden[\"\\']', html, re.I)\n",
    "    )\n",
    "    features[\"submit_button_count\"] = len(\n",
    "        re.findall(r'type\\s*=\\s*[\"\\']submit[\"\\']', html, re.I)\n",
    "    )\n",
    "\n",
    "    # Form actions\n",
    "    form_actions = re.findall(r'action\\s*=\\s*[\"\\']([^\"\\']+)[\"\\']', html, re.I)\n",
    "    features[\"form_has_external_action\"] = 0\n",
    "    features[\"form_action_suspicious\"] = 0\n",
    "\n",
    "    for action in form_actions:\n",
    "        if action.startswith(\"http\"):\n",
    "            features[\"form_has_external_action\"] = 1\n",
    "        if \".php\" in action.lower():\n",
    "            features[\"form_action_suspicious\"] = 1\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_script_features(html: str) -> Dict[str, float]:\n",
    "    \"\"\"Extract JavaScript and obfuscation features\"\"\"\n",
    "    features = {}\n",
    "\n",
    "    all_scripts = extract_all_scripts(html)\n",
    "    features[\"total_script_length\"] = len(all_scripts)\n",
    "\n",
    "    # Dangerous functions\n",
    "    features[\"has_eval\"] = 1 if \"eval(\" in all_scripts else 0\n",
    "    features[\"has_unescape\"] = 1 if \"unescape(\" in all_scripts else 0\n",
    "    features[\"has_document_write\"] = 1 if \"document.write\" in all_scripts else 0\n",
    "    features[\"has_settimeout\"] = 1 if \"setTimeout\" in all_scripts else 0\n",
    "    features[\"has_setinterval\"] = 1 if \"setInterval\" in all_scripts else 0\n",
    "\n",
    "    # Obfuscation patterns\n",
    "    features[\"has_unicode_escape\"] = 1 if re.search(r\"\\\\u[0-9a-fA-F]{4}\", html) else 0\n",
    "    features[\"has_hex_escape\"] = 1 if re.search(r\"\\\\x[0-9a-fA-F]{2}\", html) else 0\n",
    "    features[\"has_base64\"] = 1 if re.search(r\"atob\\s*\\(\", all_scripts) else 0\n",
    "    features[\"has_packed_js\"] = (\n",
    "        1 if re.search(r\"eval\\s*\\(\\s*function\\s*\\(\", all_scripts) else 0\n",
    "    )\n",
    "    features[\"has_charcodeat\"] = 1 if \"charCodeAt\" in all_scripts else 0\n",
    "    features[\"has_fromcharcode\"] = 1 if \"fromCharCode\" in all_scripts else 0\n",
    "\n",
    "    # Encoding counts\n",
    "    features[\"unicode_escape_count\"] = len(re.findall(r\"\\\\u[0-9a-fA-F]{4}\", html))\n",
    "    features[\"url_encoding_count\"] = len(re.findall(r\"%[0-9a-fA-F]{2}\", html))\n",
    "\n",
    "    # Shannon entropy\n",
    "    features[\"js_entropy\"] = (\n",
    "        calculate_shannon_entropy(all_scripts) if all_scripts else 0.0\n",
    "    )\n",
    "    features[\"high_entropy_js\"] = 1 if features[\"js_entropy\"] > 5.0 else 0\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_url_features(html: str, page_url: Optional[str] = None) -> Dict[str, float]:\n",
    "    \"\"\"Extract features from URLs and links\"\"\"\n",
    "    features = {}\n",
    "\n",
    "    hrefs = re.findall(r'href\\s*=\\s*[\"\\']([^\"\\']+)[\"\\']', html, re.I)\n",
    "\n",
    "    features[\"total_links\"] = len(hrefs)\n",
    "    features[\"external_links\"] = 0\n",
    "    features[\"suspicious_tld_count\"] = 0\n",
    "    features[\"ip_in_url\"] = 0\n",
    "\n",
    "    suspicious_tlds = [\".tk\", \".ml\", \".ga\", \".cf\", \".gq\", \".info\", \".xyz\"]\n",
    "\n",
    "    for href in hrefs:\n",
    "        if href.startswith(\"http\"):\n",
    "            features[\"external_links\"] += 1\n",
    "\n",
    "            if any(tld in href.lower() for tld in suspicious_tlds):\n",
    "                features[\"suspicious_tld_count\"] += 1\n",
    "\n",
    "            if re.search(r\"https?://\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\", href):\n",
    "                features[\"ip_in_url\"] = 1\n",
    "\n",
    "    features[\"external_resources\"] = len(re.findall(r'src\\s*=\\s*[\"\\']http', html, re.I))\n",
    "\n",
    "    # URL-text mismatch\n",
    "    link_patterns = re.findall(\n",
    "        r'<a[^>]+href\\s*=\\s*[\"\\']([^\"\\']+)[\"\\'][^>]*>([^<]*)</a>', html, re.I\n",
    "    )\n",
    "    features[\"url_text_mismatch\"] = 0\n",
    "\n",
    "    for url, text in link_patterns:\n",
    "        text_clean = text.strip().lower()\n",
    "        if re.search(r\"[a-z0-9-]+\\.(com|net|org)\", text_clean) and url.startswith(\n",
    "            \"http\"\n",
    "        ):\n",
    "            if text_clean not in url.lower():\n",
    "                features[\"url_text_mismatch\"] = 1\n",
    "                break\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_visual_features(html: str) -> Dict[str, float]:\n",
    "    \"\"\"Analyze visual layout patterns\"\"\"\n",
    "    features = {}\n",
    "\n",
    "    # Image-to-text ratio\n",
    "    img_tags = re.findall(r\"<img[^>]*>\", html, re.I)\n",
    "    total_img_area = 0\n",
    "\n",
    "    for img in img_tags:\n",
    "        width = re.search(r'width\\s*=\\s*[\"\\']?(\\d+)', img, re.I)\n",
    "        height = re.search(r'height\\s*=\\s*[\"\\']?(\\d+)', img, re.I)\n",
    "        if width and height:\n",
    "            total_img_area += int(width.group(1)) * int(height.group(1))\n",
    "\n",
    "    text_length = len(get_text_content(html).strip())\n",
    "    features[\"total_image_area\"] = total_img_area\n",
    "    features[\"image_to_text_ratio\"] = safe_divide(total_img_area, text_length)\n",
    "    features[\"high_image_to_text\"] = 1 if features[\"image_to_text_ratio\"] > 100 else 0\n",
    "\n",
    "    # Z-index patterns\n",
    "    z_indices = [int(z) for z in re.findall(r\"z-index\\s*:\\s*(\\d+)\", html, re.I)]\n",
    "    features[\"max_z_index\"] = max(z_indices) if z_indices else 0\n",
    "    features[\"z_index_range\"] = (\n",
    "        max(z_indices) - min(z_indices) if len(z_indices) > 1 else 0\n",
    "    )\n",
    "    features[\"high_z_index_elements\"] = sum(1 for z in z_indices if z > 100)\n",
    "\n",
    "    # Positioning\n",
    "    features[\"absolute_position_count\"] = len(\n",
    "        re.findall(r\"position\\s*:\\s*absolute\", html, re.I)\n",
    "    )\n",
    "    features[\"overlay_pattern\"] = (\n",
    "        1\n",
    "        if (features[\"absolute_position_count\"] > 3 and features[\"max_z_index\"] > 10)\n",
    "        else 0\n",
    "    )\n",
    "\n",
    "    # Hidden elements\n",
    "    features[\"font_size_zero\"] = len(re.findall(r\"font-size\\s*:\\s*0\", html, re.I))\n",
    "    features[\"opacity_zero\"] = len(re.findall(r\"opacity\\s*:\\s*0\", html, re.I))\n",
    "    features[\"negative_position\"] = len(\n",
    "        re.findall(r\"(left|top)\\s*:\\s*-\\d{3,}px\", html, re.I)\n",
    "    )\n",
    "    features[\"display_none\"] = len(re.findall(r\"display\\s*:\\s*none\", html, re.I))\n",
    "    features[\"hidden_text_techniques\"] = (\n",
    "        features[\"font_size_zero\"]\n",
    "        + features[\"opacity_zero\"]\n",
    "        + features[\"negative_position\"]\n",
    "    )\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_behavioral_features(html: str) -> Dict[str, float]:\n",
    "    \"\"\"Detect suspicious behavioral patterns\"\"\"\n",
    "    features = {}\n",
    "\n",
    "    all_scripts = extract_all_scripts(html)\n",
    "\n",
    "    # Delayed modifications\n",
    "    features[\"delayed_password_reveal\"] = (\n",
    "        1\n",
    "        if re.search(r\"setTimeout.*type.*password\", all_scripts, re.I | re.DOTALL)\n",
    "        else 0\n",
    "    )\n",
    "\n",
    "    dom_patterns = [\n",
    "        r\"setTimeout.*innerHTML\",\n",
    "        r\"setTimeout.*createElement\",\n",
    "        r\"setTimeout.*appendChild\",\n",
    "        r\"setInterval.*style\",\n",
    "    ]\n",
    "    features[\"delayed_dom_modification\"] = sum(\n",
    "        1 for p in dom_patterns if re.search(p, all_scripts, re.I | re.DOTALL)\n",
    "    )\n",
    "\n",
    "    # Security blocking\n",
    "    security_patterns = [\n",
    "        r\"keydown.*preventDefault\",\n",
    "        r\"keypress.*preventDefault\",\n",
    "        r\"contextmenu.*preventDefault\",\n",
    "        r\"F12.*preventDefault\",\n",
    "        r\"inspect.*preventDefault\",\n",
    "        r\"Ctrl.*U.*preventDefault\",\n",
    "    ]\n",
    "    features[\"blocks_security_hotkeys\"] = sum(\n",
    "        1 for p in security_patterns if re.search(p, all_scripts, re.I)\n",
    "    )\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_identity_features(\n",
    "    html: str, page_url: Optional[str] = None\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Check for identity and brand mismatches\"\"\"\n",
    "    features = {}\n",
    "\n",
    "    domain = extract_domain(page_url)\n",
    "    text_content = get_text_content(html).lower()\n",
    "\n",
    "    # Brand mentions\n",
    "    mentioned_brands = [\n",
    "        brand for brand in BRAND_KEYWORDS.keys() if brand in text_content\n",
    "    ]\n",
    "    features[\"brand_mention_count\"] = len(mentioned_brands)\n",
    "    features[\"domain_brand_mismatch\"] = 0\n",
    "\n",
    "    if domain and mentioned_brands:\n",
    "        domain_matches = any(\n",
    "            any(official in domain for official in BRAND_KEYWORDS[brand])\n",
    "            for brand in mentioned_brands\n",
    "        )\n",
    "        features[\"domain_brand_mismatch\"] = 0 if domain_matches else 1\n",
    "\n",
    "    # Form action analysis\n",
    "    form_actions = re.findall(r'action\\s*=\\s*[\"\\']([^\"\\']+)[\"\\']', html, re.I)\n",
    "    features[\"form_action_to_free_host\"] = 0\n",
    "    features[\"form_action_different_domain\"] = 0\n",
    "\n",
    "    for action in form_actions:\n",
    "        if any(free_host in action.lower() for free_host in FREE_HOSTING_DOMAINS):\n",
    "            features[\"form_action_to_free_host\"] = 1\n",
    "\n",
    "        if action.startswith(\"http\") and domain:\n",
    "            action_domain = extract_domain(action)\n",
    "            if action_domain and action_domain != domain:\n",
    "                features[\"form_action_different_domain\"] = 1\n",
    "\n",
    "    # Favicon\n",
    "    features[\"has_favicon\"] = (\n",
    "        1 if re.search(r'rel\\s*=\\s*[\"\\'][^\"\\']*icon[^\"\\']*[\"\\']', html, re.I) else 0\n",
    "    )\n",
    "    favicon_urls = re.findall(\n",
    "        r'rel\\s*=\\s*[\"\\'][^\"\\']*icon[^\"\\']*[\"\\'][^>]*href\\s*=\\s*[\"\\']([^\"\\']+)[\"\\']',\n",
    "        html,\n",
    "        re.I,\n",
    "    )\n",
    "    features[\"favicon_external\"] = 0\n",
    "    if favicon_urls and domain:\n",
    "        features[\"favicon_external\"] = (\n",
    "            1\n",
    "            if any(f.startswith(\"http\") and domain not in f for f in favicon_urls)\n",
    "            else 0\n",
    "        )\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_semantic_features(\n",
    "    html: str, page_url: Optional[str] = None\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Analyze semantic relationships in the DOM\"\"\"\n",
    "    features = {}\n",
    "\n",
    "    # Brand-password proximity\n",
    "    text_with_brands = [\n",
    "        brand for brand in BRAND_KEYWORDS.keys() if brand in html.lower()\n",
    "    ]\n",
    "    features[\"brands_near_password_field\"] = 0\n",
    "\n",
    "    if text_with_brands:\n",
    "        password_positions = [\n",
    "            m.start() for m in re.finditer(r'type\\s*=\\s*[\"\\']password[\"\\']', html, re.I)\n",
    "        ]\n",
    "\n",
    "        for brand in text_with_brands:\n",
    "            brand_positions = [m.start() for m in re.finditer(brand, html, re.I)]\n",
    "            for p_pos in password_positions:\n",
    "                for b_pos in brand_positions:\n",
    "                    if abs(p_pos - b_pos) < 500:\n",
    "                        features[\"brands_near_password_field\"] = 1\n",
    "                        break\n",
    "\n",
    "    # Title analysis\n",
    "    title_match = re.search(r\"<title[^>]*>([^<]+)</title>\", html, re.I)\n",
    "    features[\"title_has_brand\"] = 0\n",
    "    features[\"brand_password_distance\"] = 0\n",
    "    features[\"brand_password_far\"] = 0\n",
    "\n",
    "    if title_match:\n",
    "        title_text = title_match.group(1).lower()\n",
    "        title_has_brand = any(brand in title_text for brand in BRAND_KEYWORDS.keys())\n",
    "        features[\"title_has_brand\"] = 1 if title_has_brand else 0\n",
    "\n",
    "        if title_has_brand and re.search(r'type\\s*=\\s*[\"\\']password[\"\\']', html, re.I):\n",
    "            title_pos = title_match.start()\n",
    "            password_positions = [\n",
    "                m.start()\n",
    "                for m in re.finditer(r'type\\s*=\\s*[\"\\']password[\"\\']', html, re.I)\n",
    "            ]\n",
    "            min_distance = min(abs(title_pos - p_pos) for p_pos in password_positions)\n",
    "            features[\"brand_password_distance\"] = min_distance\n",
    "            features[\"brand_password_far\"] = 1 if min_distance > 2000 else 0\n",
    "\n",
    "    # External resource analysis\n",
    "    domain = extract_domain(page_url)\n",
    "    all_resources = []\n",
    "    all_resources.extend(re.findall(r'src\\s*=\\s*[\"\\']([^\"\\']+)[\"\\']', html, re.I))\n",
    "    all_resources.extend(\n",
    "        re.findall(r'href\\s*=\\s*[\"\\']([^\"\\']+\\.css[^\"\\']*)[\"\\']', html, re.I)\n",
    "    )\n",
    "    all_resources.extend(\n",
    "        re.findall(r'<script[^>]+src\\s*=\\s*[\"\\']([^\"\\']+)[\"\\']', html, re.I)\n",
    "    )\n",
    "\n",
    "    external_resources = [r for r in all_resources if r.startswith(\"http\")]\n",
    "\n",
    "    features[\"total_resources\"] = len(all_resources)\n",
    "    features[\"external_resources\"] = len(external_resources)\n",
    "    features[\"official_brand_resources\"] = 0\n",
    "    features[\"ratio_official_assets\"] = 0\n",
    "    features[\"hotlinking_official_assets\"] = 0\n",
    "\n",
    "    if external_resources:\n",
    "        for resource in external_resources:\n",
    "            resource_lower = resource.lower()\n",
    "            for brand, official_domains in BRAND_KEYWORDS.items():\n",
    "                if any(official in resource_lower for official in official_domains):\n",
    "                    features[\"official_brand_resources\"] += 1\n",
    "                    break\n",
    "\n",
    "        features[\"ratio_official_assets\"] = safe_divide(\n",
    "            features[\"official_brand_resources\"], len(external_resources)\n",
    "        )\n",
    "\n",
    "        if features[\"ratio_official_assets\"] > 0.5 and domain:\n",
    "            is_official = any(\n",
    "                any(official in domain for official in domains)\n",
    "                for domains in BRAND_KEYWORDS.values()\n",
    "            )\n",
    "            features[\"hotlinking_official_assets\"] = 0 if is_official else 1\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_content_features(html: str) -> Dict[str, float]:\n",
    "    \"\"\"Extract features from visible text and keywords\"\"\"\n",
    "    features = {}\n",
    "\n",
    "    text = get_text_content(html).lower()\n",
    "\n",
    "    features[\"text_length\"] = len(text)\n",
    "    features[\"word_count\"] = len(text.split())\n",
    "    features[\"phishing_keyword_count\"] = sum(\n",
    "        1 for keyword in PHISHING_KEYWORDS if keyword in text\n",
    "    )\n",
    "    features[\"exclamation_count\"] = text.count(\"!\")\n",
    "    features[\"question_count\"] = text.count(\"?\")\n",
    "    features[\"special_char_ratio\"] = safe_divide(\n",
    "        len(re.findall(r\"[^a-zA-Z0-9\\s]\", text)), len(text)\n",
    "    )\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_all_features(\n",
    "    html: str,\n",
    "    page_url: Optional[str] = None,\n",
    "    rec_id: Optional[int] = None,\n",
    "    result: Optional[int] = None,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Extract all phishing detection features from HTML.\n",
    "\n",
    "    Args:\n",
    "        html: HTML content as string\n",
    "        page_url: Optional URL of the page\n",
    "        rec_id: Optional record ID\n",
    "        result: Optional label (0=legit, 1=phishing)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of all extracted features\n",
    "    \"\"\"\n",
    "    if pd.isna(html) or html == \"\":\n",
    "        return {}\n",
    "\n",
    "    try:\n",
    "        features = {}\n",
    "\n",
    "        # Extract all feature categories\n",
    "        features.update(extract_structural_features(html))\n",
    "        features.update(extract_form_features(html))\n",
    "        features.update(extract_script_features(html))\n",
    "        features.update(extract_url_features(html, page_url))\n",
    "        features.update(extract_visual_features(html))\n",
    "        features.update(extract_behavioral_features(html))\n",
    "        features.update(extract_identity_features(html, page_url))\n",
    "        features.update(extract_semantic_features(html, page_url))\n",
    "        features.update(extract_content_features(html))\n",
    "\n",
    "        # Add metadata\n",
    "        if rec_id is not None:\n",
    "            features[\"rec_id\"] = rec_id\n",
    "        if result is not None:\n",
    "            features[\"result\"] = result\n",
    "\n",
    "        return features\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features: {str(e)[:100]}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "def process_dataset(dataset: pd.DataFrame, batch_size: int = 1000) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process entire dataset and extract features.\n",
    "\n",
    "    Args:\n",
    "        dataset: DataFrame with columns: webpage_code, url, rec_id, result\n",
    "        batch_size: Number of rows to process before showing progress\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with all extracted features\n",
    "    \"\"\"\n",
    "    print(f\"Processing {len(dataset)} rows...\")\n",
    "    features_list = []\n",
    "\n",
    "    for idx, row in dataset.iterrows():\n",
    "        if idx % batch_size == 0:\n",
    "            print(f\"Progress: {idx}/{len(dataset)} ({idx/len(dataset)*100:.1f}%)\")\n",
    "\n",
    "        features = extract_all_features(\n",
    "            html=row.get(\"webpage_code\", \"\"),\n",
    "            page_url=row.get(\"url\", None),\n",
    "            rec_id=row.get(\"rec_id\", None),\n",
    "            result=row.get(\"result\", None),\n",
    "        )\n",
    "        features_list.append(features)\n",
    "\n",
    "    print(f\"Progress: {len(dataset)}/{len(dataset)} (100.0%)\")\n",
    "    return pd.DataFrame(features_list)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"PHISHING FEATURE EXTRACTION\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Load dataset\n",
    "    print(\"\\n1. Loading dataset...\")\n",
    "    dataset = pd.read_csv(\n",
    "        \"/kaggle/input/phishing-complete-dataset-preprocessed/phishing_complete_dataset_preprocessed.csv\"\n",
    "    )\n",
    "    print(f\"   ✓ Loaded: {dataset.shape}\")\n",
    "\n",
    "    # Clean dataset\n",
    "    print(\"\\n2. Cleaning dataset...\")\n",
    "    original_size = len(dataset)\n",
    "    dataset.dropna(inplace=True)\n",
    "    dataset.drop_duplicates(inplace=True)\n",
    "    print(f\"   ✓ Removed {original_size - len(dataset)} rows\")\n",
    "    print(f\"   ✓ Final size: {dataset.shape}\")\n",
    "\n",
    "    # Extract features\n",
    "    print(\"\\n3. Extracting features...\")\n",
    "    features_df = process_dataset(dataset, batch_size=1000)\n",
    "\n",
    "    print(\"\\n4. Feature extraction complete!\")\n",
    "    print(\n",
    "        f\"   ✓ Total features: {len(features_df.columns) - 2}\"\n",
    "    )  # -2 for rec_id and result\n",
    "\n",
    "    # Show sample\n",
    "    print(\"\\n5. Sample features (first 10):\")\n",
    "    print(\"-\" * 60)\n",
    "    for i, (key, value) in enumerate(features_df.iloc[0].items()):\n",
    "        if i < 10:\n",
    "            print(f\"   {key}: {value}\")\n",
    "\n",
    "    # Statistics\n",
    "    print(\"\\n6. Feature statistics:\")\n",
    "    print(\"-\" * 60)\n",
    "    numeric_cols = features_df.select_dtypes(include=[np.number]).columns\n",
    "    numeric_cols = [col for col in numeric_cols if col not in [\"rec_id\", \"result\"]]\n",
    "    print(features_df[numeric_cols].describe().round(2))\n",
    "\n",
    "    # Save\n",
    "    print(\"\\n7. Saving features...\")\n",
    "    output_path = \"/kaggle/working/phishing_complete_features.csv\"\n",
    "    features_df.to_csv(output_path, index=False)\n",
    "    print(f\"   ✓ Saved to: {output_path}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"✓ FEATURE EXTRACTION COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    return features_df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    features_df = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
